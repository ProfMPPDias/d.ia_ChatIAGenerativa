# d.IA - IA Generativa

**d.IA** √© uma IA generativa de texto constru√≠da com Python, Flask e a API do Ollama. A aplica√ß√£o permite que os usu√°rios interajam com um chatbot que gera respostas com base no texto enviado. A interface do chatbot √© projetada com uma janela personaliz√°vel e arrast√°vel em um tema moderno.

## üöÄ Funcionalidades

- **IA Generativa**: Utiliza a API do Ollama para gerar respostas em tempo real.
- **Janela de Chat Arrast√°vel**: O usu√°rio pode mover a janela de chat livremente pela tela.
- **Modo Escuro**: A interface √© estilizada com o tema Dracula para um visual moderno e elegante.
- **Fun√ß√£o de Copiar Mensagem**: O usu√°rio pode copiar qualquer resposta da IA com um clique no bot√£o.
- **Intera√ß√£o em Tempo Real**: Converse com a IA em tempo real, com respostas entregues quase instantaneamente.

## üîß Tecnologias Utilizadas

- **Python**: Para a l√≥gica de backend e opera√ß√µes do servidor.
- **Flask**: Framework web leve para Python.
- **Ollama**: Fornece as respostas geradas pela IA.
- **HTML/CSS/JS**: Para a interface de usu√°rio frontend.

## üåê Configura√ß√£o e Instala√ß√£o

### Pr√©-requisitos

Certifique-se de que voc√™ tem o seguinte instalado:

- Python 3.7+
- pip (gerenciador de pacotes do Python)
- Ollama (https://ollama.com/)

### Passo-a-Passo na Implementa√ß√£o

1. Clone o reposit√≥rio:

   ```bash
   git clone https://github.com/seu-usuario/d.IA.git
   cd d.IA
   ```
   
2. Instale as depend√™ncias:

```bash
pip install -r requirements.txt
```

3. Inicie o Servidor Flask

```bash
python main.py
```

4. Instale o Ollama, verifique qual sistema operacional ir√° usado (no servidor ou local);
   
5. Ap√≥s instala√ß√£o, fa√ßa o comando para instalar a rede neural Llama 3.2 em sua √∫ltima vers√£o, Llama 3.2:
   
```bash
ollama pull llama3.2
```

6. Finalmente, execute a rede neural do Llama 3.2:

```bash
ollama run llama3.2
```
7. Repare, que ao iniciar o Servidor Flask, voc√™ dever√° fazer o passo √° passo da Rede Neural do Llama em uma outra aba do CMD, PowerShell ou Terminal.

8. Caso esteja rodando em uma VPS, dever√° utilizar o screen para gerenciar uma √°rea de trabalho nova.

## üõ†Ô∏è Configura√ß√£o da API

A aplica√ß√£o utiliza rede neural baseada no Ollama para gerar as respostas de texto. Por padr√£o, o servidor deve estar rodando em http://0.0.0.0:11434/api/chat. 
Caso tenha a API do Ollama rodando em outro host ou porta, ser√° necess√°rio modificar a URL OLLAMA_URL no arquivo main.py.

## üí° Como Usar

- Abra o aplicativo no seu navegador.
- Digite uma mensagem no campo de entrada e pressione "Enviar".
- O chatbot gerar√° uma resposta com base na sua mensagem.
- Voc√™ pode arrastar a janela de chat pela tela, clicando e segurando o cabe√ßalho.

## üôè Contribuindo

- Fique √† vontade para fazer um fork deste reposit√≥rio, enviar problemas e criar pull requests para contribuir.
